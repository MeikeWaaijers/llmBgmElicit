% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/elicitEdgeProb.R
\name{elicitEdgeProb}
\alias{elicitEdgeProb}
\title{Elicit Prior Edge Inclusion Probabilities Using a LLM}
\usage{
elicitEdgeProb(
  context,
  variable_list,
  LLM_model = "gpt-4",
  update_key = FALSE,
  n_perm = NULL,
  seed = 123,
  main_prompt = NULL,
  display_progress = TRUE,
  logprobs = TRUE
)
}
\arguments{
\item{context}{Optional character string providing background information or study context
to be incorporated into the LLM prompt. Defaults to \code{NULL}.}

\item{variable_list}{A character vector of variable names. Must contain at least three variables.}

\item{LLM_model}{Character string indicating which LLM to use. Current options include:
\code{"gpt-4o"}, \code{"gpt-4-turbo"},  \code{"gpt-3.5-turbo"}, \code{"gpt-5"}, \code{"gpt-5-mini"}, or \code{"gpt-5-nano"}}

\item{update_key}{Logical. If \code{TRUE}, updates the API key used for the LLM call. Default is \code{FALSE}.
Only the first call will use the updated key. Default is \code{FALSE}.}

\item{n_perm}{Integer or \code{NULL}. Number of random permutations of pair orders to evaluate.
If \code{NULL}, two permutations are generated by default. The maximum is 50.}

\item{seed}{Integer. Random seed for reproducibility of the permutations. Default is \code{123}.}

\item{main_prompt}{Optional vector of character strings to be used as a system prompt for the LLM.
If \code{NULL}, a default system prompt is used. The prompt should be a single string.}

\item{display_progress}{Logical. If \code{TRUE}, displays progress messages during processing. Default is \code{TRUE}.}

\item{logprobs}{Logical. If \code{TRUE}, requests log probabilities from the LLM for the first token. Only available
for models that support logprobs (e.g., \verb{gpt-4o}, \code{gpt-4-turbo}, \code{gpt-3.5-turbo}). Default is \code{FALSE}.
if LLM_model does not support logprobs, this argument is ignored.}
}
\value{
A list of class \code{"elicitEdgeProb"} with the following elements:
\describe{
\item{\code{relation_df}}{A data frame with columns \code{var1}, \code{var2}, and \code{prob}, containing the elicited
prior probabilities of conditional associations between variable pairs.}
\item{\code{raw_LLM}}{A data frame of all raw LLM prompt-response data and token probabilities.}
\item{\code{diagnostics}}{A list with counts of how many times each mode was used.}
\item{\code{inclusion_probability_matrix}}{A symmetric matrix of the elicited edge inclusion probabilities
ready to be used for the Nernoulli prior in the \code{easybgm} package. Note probabilities that were
elicited to be 1 or 0 are squashed to 0.99 and 0.01, respectively, to avoid exact 0/1 probabilities,
since this is not supported in the BGM estimation packages.
\item{\code{arguments}}{A list of the function input arguments for reproducibility.}
}
}
\description{
This function queries a large language model (LLM) to elicit prior probabilities
about conditional associations (edges) between variable pairs in a Markov random field,
using constrained binary responses ('I'/'E') for optimal probability extraction.
Therefore it explicitly restricts the output of the LLM to one token.
}
\details{
The function iteratively evaluates each variable pair, updating a decision context
that is passed to the LLM to consider previous decisions. It returns edge probabilities
averaged across sampled permutations of pair orders.

Each pair is evaluated in the context of previously judged pairs, based on the current permutation.
The returned probabilities are averaged across permutations.
}
\examples{
\dontrun{
result <- elicitEdgeProb(
  context = "This study investigates the relationship between anxiety, sleep,
  and concentration.",
  variable_list = c("Anxiety", "Sleep", "Concentration"),
  LLM_model = "gpt-4o",
  n_perm = 2
)
print(result$relation_df)
}

}
