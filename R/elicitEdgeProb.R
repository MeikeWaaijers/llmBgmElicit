#' Elicit Prior Edge Inclusion Probabilities Using a LLM
#' by explicitly taking into account the LLMs decision for the remaining
#' variables
#'
#' This function queries a large language model (LLM) to elicit prior probabilities
#' about conditional associations (edges) between variable pairs in a Markov random field,
#' using constrained binary responses ('I'/'E') for optimal probability extraction.
#' Therefore it explicitly restricts the output of the LLM to one token.
#'
#' The function iteratively evaluates each variable pair, updating a decision context
#' that is passed to the LLM to consider previous decisions. It returns edge probabilities
#' averaged across sampled permutations of pair orders.
#'
#' @param context Optional character string providing background information or study context
#'   to be incorporated into the LLM prompt. Defaults to `NULL`.
#' @param variable_list A character vector of variable names. Must contain at least three variables.
#' @param LLM_model Character string indicating which LLM to use. Current options include:
#'   `"gpt-4o"`, `"gpt-4-turbo"`, or `"gpt-3.5-turbo"`
#' @param update_key Logical. If `TRUE`, updates the API key used for the LLM call. Default is `FALSE`.
#'   Only the first call will use the updated key. Default is `FALSE`.
#' @param n_perm Integer or `NULL`. Number of random permutations of pair orders to evaluate.
#'   If `NULL`, two permutations are generated by default. The maximum is 50.
#' @param seed Integer. Random seed for reproducibility of the permutations. Default is `123`.
#' @param main_prompt Optional vector of character strings to be used as a system prompt for the LLM.
#' If `NULL`, a default system prompt is used. The prompt should be a single string.
#' #' @param display_progress Logical. If `TRUE`, displays progress messages during processing. Default is `TRUE`.
#'
#' @return A list of class `"elicitEdgeProb"` with the following elements:
#' \describe{
#'   \item{`relation_df`}{A data frame with columns `var1`, `var2`, and `prob`, representing
#'     the prior probability of a conditional association between variable pairs.}
#'   \item{`raw_LLM`}{A data frame with raw responses and prompt metadata for each pair across permutations.}
#'   \item{`arguments`}{A list with the function call arguments for reproducibility.}
#' }
#'
#' @details
#' Each pair is evaluated in the context of previously judged pairs, based on the current permutation.
#' The returned probabilities are averaged across permutations.
#'
#' @examples
#' \dontrun{
#' result <- elicitEdgeProb(
#'   context = "This study investigates the relationship between anxiety, sleep,
#'   and concentration.",
#'   variable_list = c("Anxiety", "Sleep", "Concentration"),
#'   LLM_model = "gpt-4o",
#'   n_perm = 2
#' )
#' print(result$relation_df)
#' }
#'
#' @export

elicitEdgeProb <- function(context,
                           variable_list,
                           LLM_model = "gpt-4",
                           update_key = FALSE,
                           n_perm = NULL,
                           seed = 123,
                           main_prompt = NULL,
                           display_progress = TRUE) {
  # Argument validation (as before)
  stopifnot(is.character(context) | is.null(context))
  stopifnot(is.vector(variable_list) && length(variable_list) >= 3)
  stopifnot(all(sapply(variable_list, is.character)))

  # Generate pairs and permutations (as before)
  pairs_df <- data.frame(var1 = character(), var2 = character())
  for(i in 1:(length(variable_list)-1)) {
    for(j in (i+1):length(variable_list)) {
      pairs_df <- rbind(pairs_df, data.frame(var1 = variable_list[[i]], var2 = variable_list[[j]]))
    }
  }
  n_pairs <- nrow(pairs_df)
  if (missing(n_perm)) {
    n_perm <- 2
    message("The n_perm argument was not specified. The function will proceed using two permutations of the variable pair order.")
  }
  if (!missing(n_perm) && n_perm == 0) stop("n_perm cannot be zero.")
  if (n_perm > 50) stop("Requested `n_perm` (", n_perm, ") exceeds maximum possible permutations which is set to 50.")

  set.seed(seed)
  perms <- t(replicate(n_perm, sample(1:n_pairs, n_pairs, replace = FALSE), simplify = TRUE))

  raw_LLM <- list()
  logprobs_LLM <- list()
  prob_relation_df <- NULL

  for (perm_idx in 1:n_perm) {
    current_order <- perms[perm_idx, ]
    previous_decisions <- list()
    raw_LLM_perm <- list()
    logprobs_LLM_perm <- list()

    for (pair_order in 1:n_pairs) {
      i <- current_order[pair_order]
      var1 <- pairs_df[i, 1]
      var2 <- pairs_df[i, 2]
      remaining_vars <- setdiff(variable_list, c(var1, var2))
      prev_decisions_str <- if (length(previous_decisions) > 0) {
        paste(sapply(previous_decisions, function(x) {
          sprintf("'%s' & '%s': %s", x$var1, x$var2, x$decision)
        }), collapse = "\n")
      } else {
        "No previous decisions"
      }

      # New PROMPT: only 'I' or 'E' as output, but pass previous decisions/context
      prompt <- paste0(
        if (!is.null(context)) paste0("Context: ", context, "\n") else "",
        "Previous decisions in this network:\n", prev_decisions_str, "\n",
        "Current pair: '", var1, "' & '", var2, "'\n",
        "Remaining variables: ", paste(remaining_vars, collapse = ", "), "\n",
        "Respond ONLY with 'I' (included) or 'E' (excluded). Do not write anything else."
      )  # try giving the example here!

      # specify the system prompt
     if(!is.null(main_prompt)) {
      system_prompt <- main_prompt
     } else{
      system_prompt <-"You are an expert in using graphical models to study psychological constructs. You will be asked to classify whether there is a conditional relationship between pairs of variables in a Markov random field grapical model, applied to psychological research. If a conditional association exists, it means that the variables remain related even after accounting for the relationships between the other variables in the network. However, if the other variables explain away the relation between the two variables, then an edge should be absent. Consider the example that the relation between ice cream sales and number of shark attacks dissapears when we take into account the outside temperature. You must use your vast prior knowledge of the relationships between the variables to make informed decisions. When presented with two variable names, you should evaluate whether or not there is an edge between those two variables in the graphical model (which reflects a conditional association) between them, considering all previous decisions and remaining variables.  If there is a conditional association between two variables, then the edge should be categorized as included (by outputting 'I'). If there is no conditional association, then the edge should be categorized as excluded (by outputting 'E'). Therefore, output should be either 'I' or 'E'! Do not include any additional explanation or other text Since you must make decisions about conditional associations, be sure to consider the remaining variables when making your decision."
     }

      if(display_progress) {
        print(paste0("Processing permutation ", perm_idx, ", pair ", pair_order, "/", n_pairs, ": ", var1, " - ", var2))
      }

      # Call LLM
      LLM_output <- callLLM(
        prompt = prompt,
        LLM_model = LLM_model,
        max_tokens = 1,
        temperature = 0,
        logprobs = TRUE,
        raw_output = TRUE,
        system_prompt = system_prompt,
        update_key = update_key
      )
      update_key <- FALSE

      raw_LLM_perm[[pair_order]] <- c(prompt = prompt, system_prompt = system_prompt, LLM_output$raw_content)
      logprobs_LLM_perm[[pair_order]] <- LLM_output$top5_tokens

      # Store decision for chaining
      decision <- parseDecision(LLM_output$raw_content$content)
      previous_decisions[[pair_order]] <- list(var1 = var1, var2 = var2, decision = decision)
    }

    raw_LLM[[perm_idx]] <- raw_LLM_perm
    logprobs_LLM[[perm_idx]] <- logprobs_LLM_perm
  }

  # New unified processing: always use the FIRST token logprobs for all models ---
  prob_matrix <- matrix(NA, nrow = n_pairs, ncol = n_perm)
  valid_tokens <- c("i", "e")
  n_default_05 <- 0
  for (perm_idx in 1:n_perm) {
    for (pair_order in 1:n_pairs) {
      pair_idx <- perms[perm_idx, pair_order]
      first_token_data <- logprobs_LLM[[perm_idx]][[pair_order]][[1]]  # first token only
      prob_i <- 0
      prob_e <- 0
      for (m in 1:nrow(first_token_data)) {
        token <- trimws(tolower(first_token_data$top5_tokens[m]))
        if (token == "i") prob_i <- prob_i + as.numeric(first_token_data$probability[m])
        if (token == "e") prob_e <- prob_e + as.numeric(first_token_data$probability[m])
      }
      if (prob_i + prob_e > 0) {
        prob_matrix[pair_idx, perm_idx] <- prob_i / (prob_i + prob_e)
      } else {
        prob_matrix[pair_idx, perm_idx] <- 0.5
        n_default_05 <- n_default_05 + 1 # count how many times defaulted to 0.5
      }
    }
  }

  print(paste0("Number of edges defaulted to 0.5 (neither 'I' nor 'E' found in first token's top5): ", n_default_05, " out of ", n_perm * n_pairs, " total."))

  avg_probs <- rowMeans(prob_matrix, na.rm = TRUE)
  prob_relation_df <- data.frame(
    var1 = pairs_df[, 1],
    var2 = pairs_df[, 2],
    prob = avg_probs,
    row.names = NULL
  )

  # Prepare output
  output <- list()

  # Flatten raw_LLM output
  tryCatch({
    flattened_df_raw_LLM <- data.frame(
      permutation = integer(),
      pair_order = integer(),
      pair_index = integer(),
      var1 = character(),
      var2 = character(),
      LLM_model = character(),
      prompt = character(),
      system_prompt = character(),
      content = character(),
      finish_reason = character(),
      prompt_tokens = numeric(),
      answer_tokens = numeric(),
      total_tokens = numeric(),
      error = character(),
      first_token_prob = numeric(),
      stringsAsFactors = FALSE
    )

    for (perm_idx in 1:length(raw_LLM)) {
      # Extract the sequence of I/E decisions for this permutation
      ie_sequence <- sapply(raw_LLM[[perm_idx]], function(x) {
        substr(x$content, nchar(x$content), nchar(x$content))  # Gets last character
      })

      for (pair_order in 1:length(raw_LLM[[perm_idx]])) {
        pair_idx <- perms[perm_idx, pair_order]
        temp <- raw_LLM[[perm_idx]][[pair_order]]

        first_token_info <- if (!is.null(logprobs_LLM[[perm_idx]][[pair_order]]) &&
                                length(logprobs_LLM[[perm_idx]][[pair_order]]) > 0) {
          first_token_data <- logprobs_LLM[[perm_idx]][[pair_order]][[1]]
          data.frame(
            first_token_prob = as.numeric(first_token_data$probability[1]),
            stringsAsFactors = FALSE
          )
        } else {
          data.frame(
            first_token_prob = NA_real_,
            stringsAsFactors = FALSE
          )
        }


        current_content <- temp$content

        flattened_df_raw_LLM <- rbind(
          flattened_df_raw_LLM,
          data.frame(
            permutation = perm_idx,
            pair_order = pair_order,
            pair_index = pair_idx,
            var1 = pairs_df[pair_idx, 1],
            var2 = pairs_df[pair_idx, 2],
            LLM_model = temp$LLM_model,
            prompt = temp$prompt,
            system_prompt = temp$system_prompt,
            content = current_content,  # Modified to include sequence for last row
            finish_reason = temp$finish_reason,
            prompt_tokens = temp$prompt_tokens,
            answer_tokens = temp$answer_tokens,
            total_tokens = temp$total_tokens,
            error = ifelse(is.null(temp$error), NA, temp$error),
            first_token_prob = first_token_info$first_token_prob,
            stringsAsFactors = FALSE
          )
        )
      }
    }
    output$raw_LLM <- flattened_df_raw_LLM
  }, error = function(e) {
    cat(paste0("Warning: Unable to return raw LLM output -> ", e$message, "."),
        "Only part of the output is returned.", sep = "\n")
  })

  output$relation_df <- prob_relation_df
  print(paste0("Total of LLM prompts: ", n_perm * n_pairs))
  output$arguments <- list(
    context = context,
    variable_list = variable_list,
    LLM_model = LLM_model,
    update_key = update_key,
    n_perm = n_perm,
    seed = seed,
    n_default_05 = n_default_05
  )
  class(output) <- "elicitEdgeProb"
  return(output)
}
